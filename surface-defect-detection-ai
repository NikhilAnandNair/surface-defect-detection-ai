# =====================================================
# üß† Heat Sink Surface Defect Segmentation (U-Net)
# FINAL CLEAN VERSION (Fully Working)
# =====================================================

!pip install kaggle tqdm

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from sklearn.model_selection import train_test_split
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
import zipfile
import random
import shutil

# =====================================================
# üîΩ Download dataset from Kaggle
# =====================================================
from google.colab import files
files.upload()  # upload your kaggle.json

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d kaifengyang/heat-sink-surface-defect-dataset
!unzip -q heat-sink-surface-defect-dataset.zip -d data/

# =====================================================
# üìÇ Paths
# =====================================================
base_dir = "data/Heat_Sink_Surface_Defect_Dataset"
images_dir = os.path.join(base_dir, "images")
jsons_dir = os.path.join(base_dir, "jsons")

print("‚úÖ Checking dataset structure...")
!ls -R data/Heat_Sink_Surface_Defect_Dataset | head -30

# =====================================================
# üßπ Load and pair images + masks correctly
# =====================================================
images, masks = [], []

for img_name in tqdm(os.listdir(images_dir), desc="Pairing images and masks"):
    if not img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
        continue

    img_path = os.path.join(images_dir, img_name)
    json_folder = os.path.join(jsons_dir, img_name.replace('.bmp', '_json'))
    mask_path = os.path.join(json_folder, 'label.png')

    if not os.path.exists(mask_path):
        # skip images with missing mask folder
        continue

    try:
        # load image
        img = np.array(Image.open(img_path).convert("RGB").resize((128, 128)))
        # load mask
        mask = np.array(Image.open(mask_path).convert("L").resize((128, 128)))
        mask = (mask > 0).astype(np.float32)  # binarize mask

        images.append(img)
        masks.append(mask)
    except Exception as e:
        print(f"‚ö†Ô∏è Skipping {img_name}: {e}")

images = np.array(images)
masks = np.expand_dims(np.array(masks), axis=-1)

print(f"\n‚úÖ Loaded {len(images)} valid image‚Äìmask pairs")

if len(images) == 0:
    raise ValueError("‚ùå No valid pairs found ‚Äî check jsons/ folder paths.")

# =====================================================
# ‚úÇÔ∏è Split Train / Validation
# =====================================================
X_train, X_val, y_train, y_val = train_test_split(
    images, masks, test_size=0.2, random_state=42
)

print(f"Train: {X_train.shape}, Validation: {X_val.shape}")

# =====================================================
# üß† Define simple U-Net model
# =====================================================
def build_unet(input_shape=(128, 128, 3)):
    inputs = layers.Input(input_shape)

    # Encoder
    c1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(inputs)
    c1 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(c1)
    p1 = layers.MaxPooling2D((2,2))(c1)

    c2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(p1)
    c2 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(c2)
    p2 = layers.MaxPooling2D((2,2))(c2)

    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(p2)
    c3 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(c3)
    p3 = layers.MaxPooling2D((2,2))(c3)

    # Bottleneck
    c4 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(p3)
    c4 = layers.Conv2D(128, (3,3), activation='relu', padding='same')(c4)

    # Decoder
    u5 = layers.UpSampling2D((2,2))(c4)
    u5 = layers.Concatenate()([u5, c3])
    c5 = layers.Conv2D(64, (3,3), activation='relu', padding='same')(u5)

    u6 = layers.UpSampling2D((2,2))(c5)
    u6 = layers.Concatenate()([u6, c2])
    c6 = layers.Conv2D(32, (3,3), activation='relu', padding='same')(u6)

    u7 = layers.UpSampling2D((2,2))(c6)
    u7 = layers.Concatenate()([u7, c1])
    c7 = layers.Conv2D(16, (3,3), activation='relu', padding='same')(u7)

    outputs = layers.Conv2D(1, (1,1), activation='sigmoid')(c7)

    return models.Model(inputs, outputs)

model = build_unet()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

# =====================================================
# üèãÔ∏è Train model
# =====================================================
es = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
mc = ModelCheckpoint('best_unet_model.keras', save_best_only=True, monitor='val_loss')

history = model.fit(
    X_train / 255.0, y_train,
    validation_data=(X_val / 255.0, y_val),
    epochs=10,
    batch_size=16,
    callbacks=[es, mc]
)

# =====================================================
# üìä Plot training curves
# =====================================================
plt.figure(figsize=(8,5))
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Training Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# =====================================================
# üéØ Show sample prediction
# =====================================================
i = random.randint(0, len(X_val)-1)
pred_mask = model.predict(np.expand_dims(X_val[i]/255.0, axis=0))[0]

plt.figure(figsize=(12,4))
plt.subplot(1,3,1)
plt.title("Input")
plt.imshow(X_val[i].astype(np.uint8))
plt.axis('off')

plt.subplot(1,3,2)
plt.title("Ground Truth")
plt.imshow(y_val[i].squeeze(), cmap='gray')
plt.axis('off')

plt.subplot(1,3,3)
plt.title("Predicted Mask")
plt.imshow(pred_mask.squeeze(), cmap='gray')
plt.axis('off')
plt.show()

# =====================================================
# üíæ Save model
# =====================================================
model.save('final_unet_model.keras')

from google.colab import files
files.download('final_unet_model.keras')


